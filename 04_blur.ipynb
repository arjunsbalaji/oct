{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/oct_ca_seg/oct/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oct.startup import *\n",
    "from model import CapsNet\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from fastai.vision import *\n",
    "import mlflow.pytorch as MLPY\n",
    "from fastai.utils.mem import gpu_mem_get_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GPUMemory(total=16280, free=16270, used=10)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'DEEPCAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = loadConfigJSONToDict('configCAPS_small.json')\n",
    "config_dict['LEARNER']['lr']= 0.001\n",
    "config_dict['LEARNER']['bs'] = 16\n",
    "config_dict['LEARNER']['epochs'] = 15\n",
    "config_dict['LEARNER']['runsave_dir'] = '/workspace/oct_ca_seg/runsaves/'\n",
    "config = DeepConfig(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [sens, spec, dice, my_Dice_Loss, acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveConfigRun(dictiontary, run_dir, name):\n",
    "    with open(run_dir/name, 'w') as file:\n",
    "        json.dump(dictiontary, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocodata_path = Path('/workspace/oct_ca_seg/COCOdata/')\n",
    "train_path = cocodata_path/'train/images'\n",
    "valid_path = cocodata_path/'valid/images'\n",
    "test_path = cocodata_path/'test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_get_y = lambda image_name: Path(image_name).parent.parent/('labels/'+Path(image_name).name)\n",
    "codes = np.loadtxt(cocodata_path/'codes.txt', dtype=str)\n",
    "tfms = get_transforms()\n",
    "src = (SegCustomItemList\n",
    "       .from_folder(cocodata_path, recurse=True, extensions='.jpg')\n",
    "       .filter_by_func(lambda fname: Path(fname).parent.name == 'images', )\n",
    "       .split_by_folder('train', 'valid')\n",
    "       .label_from_func(fn_get_y, classes=codes))\n",
    "src.transform(tfms, tfm_y=True, size=config.LEARNER.img_size)\n",
    "data = src.databunch(cocodata_path,\n",
    "                     bs=config.LEARNER.bs,\n",
    "                     val_bs=2*config.LEARNER.bs,\n",
    "                     num_workers = config.LEARNER.num_workers)\n",
    "stats = [torch.tensor([0.2190, 0.1984, 0.1928]), torch.tensor([0.0645, 0.0473, 0.0434])]\n",
    "data.normalize(stats);\n",
    "data.c_in, data.c_out = 3, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For converting Validation set into a mini set to experiment on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_get_y = lambda image_name: Path(image_name).parent.parent/('labels/'+Path(image_name).name)\n",
    "codes = np.loadtxt(cocodata_path/'codes.txt', dtype=str)\n",
    "tfms = get_transforms()\n",
    "src = (SegCustomItemList\n",
    "       .from_folder(test_path, recurse=True, extensions='.jpg')\n",
    "       .filter_by_func(lambda fname: Path(fname).parent.name == 'images', )\n",
    "       .split_by_rand_pct(0.9)\n",
    "       .label_from_func(fn_get_y, classes=codes))\n",
    "src.transform(tfms, tfm_y=True, size =config.LEARNER.img_size)\n",
    "data = src.databunch(test_path,\n",
    "                     bs=config.LEARNER.bs,\n",
    "                     val_bs=2*config.LEARNER.bs,\n",
    "                     num_workers = config.LEARNER.num_workers)\n",
    "stats = [torch.tensor([0.2190, 0.1984, 0.1928]), torch.tensor([0.0645, 0.0473, 0.0434])]\n",
    "data.normalize(stats);\n",
    "data.c_in, data.c_out = 3, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GaussianSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = GaussianSmoothing(2, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 254, 254])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg(torch.rand(1,2,256,256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepCap = CapsNet(config.MODEL).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 8, 8])\n",
      "torch.Size([1, 512, 6, 6])\n",
      "torch.Size([1, 512, 8, 8])\n",
      "torch.Size([1, 128, 16, 16])\n",
      "torch.Size([1, 128, 14, 14])\n",
      "torch.Size([1, 128, 16, 16])\n",
      "torch.Size([1, 16, 32, 32])\n",
      "torch.Size([1, 16, 30, 30])\n",
      "torch.Size([1, 16, 32, 32])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 128, 62, 62])\n",
      "torch.Size([1, 128, 64, 64])\n",
      "torch.Size([1, 16, 128, 128])\n",
      "torch.Size([1, 16, 126, 126])\n",
      "torch.Size([1, 16, 128, 128])\n",
      "CPU times: user 126 ms, sys: 51.5 ms, total: 177 ms\n",
      "Wall time: 178 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0192, 0.0187, 0.0189,  ..., 0.0187, 0.0190, 0.0187],\n",
       "          [0.0188, 0.0191, 0.0185,  ..., 0.0191, 0.0184, 0.0185],\n",
       "          [0.0189, 0.0185, 0.0188,  ..., 0.0185, 0.0189, 0.0187],\n",
       "          ...,\n",
       "          [0.0184, 0.0191, 0.0183,  ..., 0.0193, 0.0182, 0.0185],\n",
       "          [0.0189, 0.0187, 0.0188,  ..., 0.0186, 0.0189, 0.0187],\n",
       "          [0.0184, 0.0183, 0.0184,  ..., 0.0186, 0.0184, 0.0183]],\n",
       "\n",
       "         [[0.0225, 0.0208, 0.0223,  ..., 0.0209, 0.0223, 0.0212],\n",
       "          [0.0223, 0.0226, 0.0222,  ..., 0.0224, 0.0222, 0.0217],\n",
       "          [0.0223, 0.0208, 0.0223,  ..., 0.0209, 0.0223, 0.0210],\n",
       "          ...,\n",
       "          [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0215],\n",
       "          [0.0223, 0.0207, 0.0223,  ..., 0.0210, 0.0222, 0.0211],\n",
       "          [0.0216, 0.0217, 0.0218,  ..., 0.0217, 0.0218, 0.0215]]]],\n",
       "       device='cuda:0', grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "deepCap(torch.rand(1,3,256,256).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seg_model Caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = config.LEARNER.runsave_dir+'/'+name\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "exp_name = 'seg_model_caps'\n",
    "mlflow_CB = partial(MLFlowTracker,\n",
    "                    exp_name=exp_name,\n",
    "                    uri='file:/workspace/oct_ca_seg/runsaves/fastai_experiments/mlruns/',\n",
    "                    params=config.config_dict,\n",
    "                    log_model=True,\n",
    "                    nb_path=\"/workspace/oct_ca_seg/oct/02_caps.ipynb\")\n",
    "deepCap = CapsNet(config.MODEL).cuda()\n",
    "learner = Learner(data = data,\n",
    "                  model = deepCap,\n",
    "                  metrics = metrics,\n",
    "                  callback_fns=mlflow_CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    learner.fit_one_cycle(config.LEARNER.epochs, slice(config.LEARNER.lr), pct_start=0.9)\n",
    "    MLPY.save_model(learner.model, run_dir+'/model')\n",
    "    save_all_results(learner, run_dir, exp_name)\n",
    "    saveConfigRun(config.config_dict, run_dir=Path(run_dir), name = 'configCAPS_APPresnet18_bs16_epochs15_lr0.001.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
