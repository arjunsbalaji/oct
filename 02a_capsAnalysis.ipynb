{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp capsAnalaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/oct_ca_seg/oct/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oct.startup import *\n",
    "from model import CapsNet\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from fastai.vision import *\n",
    "import mlflow.pytorch as MLPY\n",
    "from fastai.utils.mem import gpu_mem_get_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GPUMemory(total=16280, free=15401, used=879)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocodata_path = Path('/workspace/oct_ca_seg/COCOdata/')\n",
    "train_path = cocodata_path/'train/images'\n",
    "valid_path = cocodata_path/'valid/images'\n",
    "test_path = cocodata_path/'test/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [sens, spec, dice, my_Dice_Loss, acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsave_dir = Path('/workspace/oct_ca_seg/runsaves/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'DEEPCAP_0001_30_learnersaved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'DEEPCAP_0001_30_small_learnersaved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = runsave_dir/run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = 'configCAPS_APPresnet18_bs16_epochs15_lr0.001.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = 'configCAPS_small_bs24_epochs30_lr0.001.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadConfigRun(run_dir, name):\n",
    "    with open(run_dir/name, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dict = loadConfigRun(run_dir, cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DeepConfig(cfg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_get_y = lambda image_name: Path(image_name).parent.parent/('labels/'+Path(image_name).name)\n",
    "codes = np.loadtxt(cocodata_path/'codes.txt', dtype=str)\n",
    "tfms = get_transforms()\n",
    "src = (SegCustomItemList\n",
    "       .from_folder(cocodata_path, recurse=True, extensions='.jpg')\n",
    "       .filter_by_func(lambda fname: Path(fname).parent.name == 'images', )\n",
    "       .split_by_folder('train', 'valid')\n",
    "       .label_from_func(fn_get_y, classes=codes))\n",
    "src.transform(tfms, tfm_y=True, size=config.LEARNER.img_size)\n",
    "data = src.databunch(cocodata_path,\n",
    "                     bs=config.LEARNER.bs,\n",
    "                     val_bs=2*config.LEARNER.bs,\n",
    "                     num_workers = config.LEARNER.num_workers)\n",
    "stats = [torch.tensor([0.2190, 0.1984, 0.1928]), torch.tensor([0.0645, 0.0473, 0.0434])]\n",
    "data.normalize(stats);\n",
    "data.c_in, data.c_out = 3, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_get_y = lambda image_name: Path(image_name).parent.parent/('labels/'+Path(image_name).name)\n",
    "codes = np.loadtxt(cocodata_path/'codes.txt', dtype=str)\n",
    "tfms = get_transforms()\n",
    "src = (SegCustomItemList\n",
    "       .from_folder(test_path, recurse=True, extensions='.jpg')\n",
    "       .filter_by_func(lambda fname: Path(fname).parent.name == 'images', )\n",
    "       .split_by_rand_pct(1.0)\n",
    "       .label_from_func(fn_get_y, classes=codes))\n",
    "src.transform(tfms, tfm_y=True, size =config.LEARNER.img_size)\n",
    "data = src.databunch(test_path,\n",
    "                     bs=config.LEARNER.bs,\n",
    "                     val_bs=2*config.LEARNER.bs,\n",
    "                     num_workers = config.LEARNER.num_workers)\n",
    "stats = [torch.tensor([0.2190, 0.1984, 0.1928]), torch.tensor([0.0645, 0.0473, 0.0434])]\n",
    "data.normalize(stats);\n",
    "data.c_in, data.c_out = 3, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepCap = CapsNet(config.MODEL).cuda()\n",
    "learn = Learner(data = data,\n",
    "                  model = deepCap,\n",
    "                  metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load(run_dir/'learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis():\n",
    "    def __init__(self, learner:Learner, run_dir:Path):\n",
    "        self.learner = learner\n",
    "        self.run_dir = run_dir\n",
    "        self.metrics = pd.read_json(self.run_dir/'metrics.json')\n",
    "        self.trainL =  pd.read_json(self.run_dir/'trainL.json')\n",
    "        self.validL =  pd.read_json(self.run_dir/'validL.json')\n",
    "    \n",
    "    def remove0FromMetric(self, metric):\n",
    "        zero_dict = {k:v for (k,v) in self.results[metric].items() if v==0}\n",
    "        zero_dict = {k: v for k, v in sorted(zero_dict.items(), key=lambda item: item[1])}\n",
    "        new_dict = {k:v for (k,v) in self.results[metric].items() if v!=0}\n",
    "        new_dict = {k: v for k, v in sorted(new_dict.items(), key=lambda item: item[1])}\n",
    "        print('there were ', len(zero_dict.keys()), 'zeros in the ', metric,' list.')\n",
    "        return zero_dict, new_dict\n",
    "    \n",
    "    def histPlotMetric(self, metric, save=False):\n",
    "        #metric = one of 'dices', 'sens', 'specs', 'accs' \n",
    "        zeros, actual = self.remove0FromMetric(metric)\n",
    "        l_actual = list(actual.values())\n",
    "        l_actual = [x for x in l_actual if x==x] # get rid of nans\n",
    "        mean, std, median, max, min = np.mean(l_actual), np.std(l_actual), np.median(l_actual), np.max(l_actual), np.min(l_actual)\n",
    "        print(mean, std, median, max, min)\n",
    "        plt.hist(l_actual)\n",
    "        if save: plt.savefig(self.checkpoint_path/(metric+'.png'))\n",
    "        #return l_actual\n",
    "    \n",
    "    def showPrediction(self, id):\n",
    "        d = validCOCO.imgs[id]\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        print(id, Path(d[\"file_name\"]).name)\n",
    "\n",
    "        outputs = predictor(im)\n",
    "        v = Visualizer(im[:, :, ::-1],\n",
    "                       metadata=valid_metadata, \n",
    "                       scale=0.8, \n",
    "                       instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "                      )\n",
    "\n",
    "        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "        image_plot = ax1.imshow(v.get_image()[:, :, ::-1])\n",
    "        \n",
    "        label_full = annsToSingleBinMask(validCOCO, d['image_id']) \n",
    "        dice_loss = lossdice(self.processOutputsToMask(outputs).cpu(), torch.tensor(label_full)).item()\n",
    "        label_plot = ax2.imshow(label_full)\n",
    "        print(dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.model(data.one_batch(ds_type=DatasetType.Valid)[0].cuda()).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapsAnalysis = Analysis(learn, run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapsAnalysis.trainL.sort_index().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CapsAnalysis.metrics['dice'].sort_index().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_to(learn, n): # freeze model up to layer n\n",
    "    for i, param in enumerate(learn.model.parameters()):\n",
    "        if i<n: param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_to(learn, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(learn.model.parameters()):\n",
    "    print(i,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(0.00001), wd=0.01, pct_start=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
